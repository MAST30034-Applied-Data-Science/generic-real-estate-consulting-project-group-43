{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Data Preprocessing\n",
    "This notebook will demonstrate the proprocessing of property data in the following sequence\n",
    "1. **Data Combining**: combine `Domain data` (retrived from API) and `Old-listing data` (retrieved from webscraping)\n",
    "\n",
    "2. **Filtering for Residential Property**: By the definition of residential property from Australia Taxation Office (ATO), A residential property includes houses, units, flats and more. It refers to residential property that provides shelter and contains basic living facilities. It doesn't include vacant land. Hence we will only be including the valid ones.\n",
    "\n",
    "3. **Feature Preprocessing** We will be checking the validity of location(longitude and latitude), number of rooms (bedrooms, bathrooms, carparks), and weekly rent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import os \n",
    "import sys\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../../scripts/')\n",
    "import historical7\n",
    "from historical7 import prepro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Combining\n",
    "The preprocessing function will loop each raw file and they will be saved as curated data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/raw/historical_data/*.csv\"\n",
    "file_lst = []\n",
    "for fname in glob.glob(path):\n",
    "    file_lst.append(fname)\n",
    "\n",
    "for file in file_lst:\n",
    "    prepro(file, 'historical')\n",
    "\n",
    "newpath = r'../../data/curated/property_all' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looping and preprocess through all historical data, we concatenate them into one dataframe and save them seperately base on year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_path = \"../../data/curated/historical/*.csv\"\n",
    "file_lst2 = []\n",
    "for fname in glob.glob(curated_path):\n",
    "    file_lst2.append(fname)\n",
    "\n",
    "# combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in file_lst2 ])\n",
    "# run the following code if you want to generate a whole historical dataset. around 57MB. Thus, will not keep that in git for now.\n",
    "# export to csv\n",
    "# combined_csv.to_csv( \"../../data/curated/historical/combined_historical.csv\", index=False, encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = pd.read_csv(\"../../data/curated/API_re_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['address', 'latitude', 'longitude', 'nbed', 'nbath',\n",
    "       'ncar', 'price', 'type', 'historical_dates', 'postcode', 'year',\n",
    "       'month', 'suburb', 'weekly_rent']\n",
    "combined_csv = combined_csv[COLS]\n",
    "api_df = api_df[COLS]\n",
    "concat_df = pd.concat([combined_csv, api_df])\n",
    "concat_df = pd.concat([combined_csv, api_df])\n",
    "print(f'In total, we have {len(concat_df)} instances, where {len(api_df)} were from domain API and {len(combined_csv)} were from oldlistings.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_lst2:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.remove(\"../../data/curated/historical/combined_historical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Residential Properites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df = combined_csv[['type', 'year','weekly_rent','postcode']]\\\n",
    "        .groupby(['type'],as_index = False) \\\n",
    "        .agg(\n",
    "            {\\\n",
    "                'weekly_rent': 'mean', # count number of instances from sample\n",
    "                'postcode': 'count'\n",
    "            }\n",
    "        ) \\\n",
    "        .rename({'postcode': 'num','weekly_rent': 'averaged_wk_rent' }, axis=1)\n",
    "\n",
    "type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(type_df.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### residential type classification\n",
    "We will classify residential types into house, apartment, and other. For the 'other' type, we assume they are residential properties as there is a large amount of them (around 20% of the whole dataset), and we saw that most of them are residential properties when doing web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_lst = [\n",
    "    '- House',\n",
    "    'Cottage',\n",
    "    'Duplex',\n",
    "    'Duplex Or Semi',\n",
    "    'Duplex/semi Detach',\n",
    "    'Duplexsemi',\n",
    "    'Duplexsemi-detached',\n",
    "    'House',\n",
    "    'Houses',\n",
    "    'Residential House',\n",
    "    'Semi',\n",
    "    'Semi Detached',\n",
    "    'Semi-detached',\n",
    "    'Semi-detached/duplex',\n",
    "    'Semi-detatched',\n",
    "    'Semi-duplex',\n",
    "    'Townhouse',\n",
    "    'Villa',\n",
    "    'Villa, House',\n",
    "    'Villa, Unit, House',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_lst = [\n",
    " '2 Storey Unit',\n",
    " 'Apartment',\n",
    " 'Block Of Units',\n",
    " 'Block Units',\n",
    "  'Flat',\n",
    " 'Flat, Block Of Units',\n",
    " 'Home Unit',\n",
    " 'Studio',\n",
    " 'Unit',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_residential_lst = [\n",
    " 'Available',\n",
    " 'Available Now',\n",
    " 'Rental',\n",
    " 'Rental Property',\n",
    " 'Rental_residential',\n",
    " 'Residential',\n",
    " 'Residential Home',\n",
    " 'Residential House',\n",
    " 'Residential Lease',\n",
    " 'Residential Rentals',\n",
    " 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lst = house_lst + apt_lst + other_residential_lst\n",
    "all_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df = concat_df[concat_df['type'].isin(all_lst)]\n",
    "print(f'{len(concat_df)-len(residential_df)} instances were dropped as they were not residential rental properties, {len(residential_df)} instances were left.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#df = residential_df\n",
    "conditions = [\n",
    "    (residential_df['type'].isin(house_lst)),\n",
    "    (residential_df['type'].isin(apt_lst)),\n",
    "    (residential_df['type'].isin(other_residential_lst)),\n",
    "    ]\n",
    "values = ['House', 'Apartment', 'Other']\n",
    "residential_df['residence_type'] = np.select(conditions, values)\n",
    "residential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS = []\n",
    "for i in range(2006,2023):\n",
    "    YEARS.append(i)\n",
    "YEARS\n",
    "for year in YEARS:\n",
    "    df = residential_df[residential_df.year == year]\n",
    "    df.to_csv(f'../../data/curated/property_all/{year}_historical_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### further visual checking after only keeping rental residential properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_path = \"../../data/curated/property_all/*.csv\"\n",
    "file_lst2 = []\n",
    "for fname in glob.glob(curated_path):\n",
    "    file_lst2.append(fname)\n",
    "\n",
    "# combine all files in the list\n",
    "residential_df = pd.concat([pd.read_csv(f) for f in file_lst2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df2 = residential_df[['residence_type', 'year','weekly_rent','postcode']]\\\n",
    "        .groupby(['residence_type'],as_index = False) \\\n",
    "        .agg(\n",
    "            {\\\n",
    "                'weekly_rent': 'mean', # count number of instances from sample\n",
    "                'postcode': 'count'\n",
    "            }\n",
    "        ) \\\n",
    "        .rename({'postcode': 'num','weekly_rent': 'averaged_wk_rent' }, axis=1)\n",
    "\n",
    "type_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,15))\n",
    "ax = sns.barplot(\n",
    "    data=type_df2, x=\"num\", y=\"residence_type\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Features\n",
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.longitude.astype(str).str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.latitude.astype(str).str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df[residential_df.longitude.astype(str).str.len() == 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df[residential_df.latitude.astype(str).str.len() == 158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_value = residential_df[residential_df.latitude.astype(str).str.len() == 158].latitude.iloc[0]\n",
    "old_value1 = residential_df[residential_df.latitude.astype(str).str.len() == 158].latitude.iloc[1]\n",
    "old_value2 = residential_df[residential_df.latitude.astype(str).str.len() == 158].latitude.iloc[2]\n",
    "new_value = '-36.8826280'\n",
    "residential_df['latitude'] = residential_df['latitude'].replace([old_value],new_value)\n",
    "residential_df['latitude'] = residential_df['latitude'].replace([old_value1],new_value)\n",
    "residential_df['latitude'] = residential_df['latitude'].replace([old_value2],new_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.latitude.astype(str).str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df[residential_df.latitude.astype(str).str.len() == 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=residential_df[['nbed','ncar','nbath']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df[residential_df.nbath > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double check:\n",
    "\n",
    "https://www.realestate.com.au/property/47-barber-st-pyramid-hill-vic-3575\n",
    "\n",
    "For '47 BARBER STREET, PYRAMID HILL' since the rental price is relatively low, for this property, we google for confirmation. From google, we can tell the number of bathroom for this property is 1.0.\n",
    "\n",
    "https://www.domain.com.au/rm-6-6-corrigan-st-burwood-vic-3125-8539197\n",
    "\n",
    "This one suggests that 'RM 6/6 CORRIGAN ST, BURWOOD' is not oulier with large number of rooms and low price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.loc[residential_df['address'] == '47 BARBER STREET, PYRAMID HILL' , 'nbath'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.loc[residential_df['address'] == '47 BARBER STREET, PYRAMID HILL']\n",
    "# after removing this, we can see that the number of bedrroms are also large hence we assume there's no outliers for nbed and nbath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly rent\n",
    "#### 2013 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = residential_df[residential_df.year == 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['address','type','weekly_rent','postcode','nbed','nbath','ncar','residence_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = df_2013[COLS]\n",
    "df_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df_2013[['weekly_rent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013[df_2013['weekly_rent'] > 3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mentioned above instances are all outliers. Hence, we consider removing values outsided of 3 standard devisation.\n",
    "\n",
    "102/8 Bligh Place, Melbourne, Vic 3000: $890 per week in 2022: https://www.realestate.com.au/property-apartment-vic-melbourne-429072318\n",
    "\n",
    "15 RICHARD STREET, WILLIAMSTOWN: $1,100pw in 2022: https://www.homely.com.au/homes/15-richard-street-williamstown-vic-3016/5250272\n",
    "\n",
    "37 Murray Drive: $654 pw in 2022: https://www.propertyvalue.com.au/property/37-murray-drive-point-leo-vic-3916/12541662\n",
    "\n",
    "2 Drake Street, Mornington VIC 3931: $1,525PER WEEK in 2022: https://www.domain.com.au/property-profile2-drake-street-mornington-vic-3931\n",
    "\n",
    "55 BELEURA HILL ROAD, MORNINGTON: $1500.00 pw in 2022: https://www.homely.com.au/homes/55-beleura-hill-road-mornington-vic-3931/1269977\n",
    "\n",
    "535 Great Ocean Road Moggs Creek VIC 3231: $552 pw in 2022: https://www.propertyvalue.com.au/property/535-great-ocean-road-moggs-creek-vic-3231/11874101\n",
    "\n",
    "30 Shoreham Road Shoreham VIC 3916: $850/w in 2022: https://www.onthehouse.com.au/property/vic/shoreham-3916/30-shoreham-rd-shoreham-vic-3916-8066322\n",
    "\n",
    "148 BROUGHAM STREET, KEW: $995.00 per week in 2022: https://www.domain.com.au/148-brougham-street-kew-vic-3101-15300836\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_rent = df_2013[(np.abs(stats.zscore(df_2013.weekly_rent)) < 3)]\n",
    "print(f'{len(df_2013) - len(df_2013_rent)} instances were dropped from {len(df_2013)}, {len(df_2013_rent)} remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df_2013_rent.weekly_rent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2014 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = residential_df[residential_df.year == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df_2014[['weekly_rent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_rent = df_2014[(np.abs(stats.zscore(df_2014.weekly_rent)) < 3)]\n",
    "print(f'{len(df_2014) - len(df_2014_rent)} ({round((len(df_2014) - len(df_2014_rent))/len(df_2014)*100,2)}%) instances were dropped from {len(df_2014)}, {len(df_2014_rent)} remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df_2013_rent.weekly_rent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess rent for all\n",
    "As approaches for rental outliers detection is quite are quite similar, we apply a function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../../scripts/')\n",
    "import outlier_drop_\n",
    "from outlier_drop_ import outlier_removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    df = residential_df[residential_df.year ==year]\n",
    "    df.to_csv(f'../../data/curated/property_all/{str(year)}_historical_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_path = \"../../data/curated/property_all/*.csv\"\n",
    "property_all_lst = []\n",
    "for fname in glob.glob(curated_path):\n",
    "    property_all_lst.append(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_all_lst = sorted(property_all_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: 11 (2.1%) instances were dropped from 523, 512 remaining\n",
      "2007: 75 (1.59%) instances were dropped from 4708, 4633 remaining\n",
      "2008: 98 (1.78%) instances were dropped from 5494, 5396 remaining\n",
      "2009: 94 (1.82%) instances were dropped from 5172, 5078 remaining\n",
      "2010: 99 (1.59%) instances were dropped from 6232, 6133 remaining\n",
      "2011: 135 (1.53%) instances were dropped from 8815, 8680 remaining\n",
      "2012: 200 (1.8%) instances were dropped from 11117, 10917 remaining\n",
      "2013: 270 (2.28%) instances were dropped from 11839, 11569 remaining\n",
      "2014: 251 (1.96%) instances were dropped from 12789, 12538 remaining\n",
      "2015: 260 (1.97%) instances were dropped from 13188, 12928 remaining\n",
      "2016: 340 (2.18%) instances were dropped from 15606, 15266 remaining\n",
      "2017: 420 (2.37%) instances were dropped from 17751, 17331 remaining\n",
      "2018: 443 (2.18%) instances were dropped from 20320, 19877 remaining\n",
      "2019: 549 (2.45%) instances were dropped from 22400, 21851 remaining\n",
      "2020: 607 (2.69%) instances were dropped from 22594, 21987 remaining\n",
      "2021: 770 (2.77%) instances were dropped from 27805, 27035 remaining\n",
      "2022: 2360 (3.11%) instances were dropped from 75999, 73639 remaining\n"
     ]
    }
   ],
   "source": [
    "for path in property_all_lst:\n",
    "    outlier_removal(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "historical_path = '../../data/curated/historical'\n",
    "property_all_path = newpath\n",
    "shutil.rmtree(historical_path)\n",
    "shutil.rmtree(property_all_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
