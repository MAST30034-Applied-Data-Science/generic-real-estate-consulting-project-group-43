{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful external data links\n",
    "# ABS household related:\n",
    "# https://www.abs.gov.au/statistics/people/housing/housing-occupancy-and-costs/2019-20#data-download\n",
    "# Oldlisting hitorical data:\n",
    "# https://www.oldlistings.com.au/real-estate/VIC/Melbourne/3000/rent/780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import time\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randint\n",
    "import re\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA FORMATTING \n",
    "## initializing lists and variables\n",
    "\n",
    "# Example of html\n",
    "# <div class=\"property odd clearfix\" data-lat=\"-37.8068451\" data-lng=\"144.9608544\"> \n",
    "# <section class=\"grid-100 grid-parent\"> \n",
    "# <section class=\"grid-65 tablet-grid-65 clearfix\"> \n",
    "# <h2 class=\"address\">3808/27 THERRY STREET, MELBOURNE</h2> \n",
    "# <p class=\"property-meta bed\"><span>Bed :</span> 3</p> \n",
    "# <p class=\"property-meta bath\"><span>Bath :</span> 2</p> \n",
    "# <p class=\"property-meta car\"><span>Car :</span> 1</p> \n",
    "# <p class=\"property-meta type\"><span>Category :</span> Available Now</p> </section> \n",
    "# <section class=\"grid-35 tablet-grid-35 price\"> <span>Last Advertised Price : August 2022</span> <\n",
    "# h3>$1,050</h3> </section> \n",
    "# <section class=\"grid-100 historical-price\"> \n",
    "# <span>Historical Prices: </span> \n",
    "# <ul> <li><span>August 2022</span>$1,050</li> \n",
    "# <li><span>February 2021</span>$790</li> \n",
    "# <li><span>March 2019</span>$1,100</li> \n",
    "# <li><span>April 2017</span>$1,050</li> \n",
    "# <li><span>March 2017</span>$1,050 per week</li> \n",
    "# <li><span>February 2016</span>$1,025 per week</li> \n",
    "# <li><span>November 2014</span>$1,000 per week</li> </ul> </section> </section> </div>\n",
    "\n",
    "def html_phaser(houses):\n",
    "    count = 0\n",
    "    data = pd.DataFrame()\n",
    "    first = True\n",
    "\n",
    "    ## how long we are running the while loop for \n",
    "    n = int(len(houses)) - 1\n",
    "\n",
    "    while count <= n:\n",
    "        # running the loop through each html bin we scraped\n",
    "        sections = houses[int(count)]\n",
    "        section_list = sections.find_all('div', class_=['odd', 'even'])#{\"class\":\"property odd clearfix\"})\n",
    "        for num in section_list:\n",
    "            # getting the price: make sure to test this code a few times by itself to understand exactly which parameters will work \n",
    "            current_priceTag = num.find_all('section', {\"class\":\"grid-35 tablet-grid-35 price\"})\n",
    "            priceSection = num.find_all('section',{\"class\":\"grid-100 historical-price\"})\n",
    "            priceTags = []\n",
    "            rent_prices = []\n",
    "            rent_dates = []\n",
    "\n",
    "            try:\n",
    "                current_price = re.search(r'\\<h3\\>(.*)\\<\\/h3\\>', str(current_priceTag))\n",
    "                current_date = re.search(r'\\:[ ](.*)\\<\\/span\\>', str(current_priceTag))\n",
    "                rent_prices.append(current_price.group(1))\n",
    "                rent_dates.append(current_date.group(1))\n",
    "            except:\n",
    "                print(\"Current rent value exception\")\n",
    "\n",
    "            priceTags = priceSection[0].find_all('li')\n",
    "            for ps in priceTags:\n",
    "                try:\n",
    "                    rent = re.search(r'\\<\\/span\\>(.*)\\<\\/li\\>', str(ps))\n",
    "                    rent_prices.append(rent.group(1))\n",
    "                    date = re.search(r'\\<span\\>(.*)\\<\\/span\\>', str(ps))\n",
    "                    rent_dates.append(date.group(1))\n",
    "                except:\n",
    "                    print(\"Historical values exception\")\n",
    "\n",
    "            try:\n",
    "                lat = re.search(r'data\\-lat\\=\\\"(.*\\d)\\\"[ ]', str(num)) \n",
    "                lng = re.search(r'data\\-lng\\=\\\"(.*\\d)\\\"\\>', str(num)) \n",
    "                latitude = lat.group(1)\n",
    "                longitude = lng.group(1)\n",
    "            except:\n",
    "                print(\"Location values exception\")\n",
    "\n",
    "            try:\n",
    "                nbed = num.find_all('p', {\"class\": \"property-meta bed\"})[0].text\n",
    "                nbed = re.search(r'[A-Za-z][ ]:[ ](.*)', nbed).group(1)\n",
    "            except IndexError:\n",
    "                nbed = 'none'\n",
    "            try:\n",
    "                nbath = num.find_all('p', {\"class\": \"property-meta bath\"})[0].text\n",
    "                nbath = re.search(r'[A-Za-z][ ]:[ ](.*)', nbath).group(1)\n",
    "            except IndexError:\n",
    "                nbath = 'none'\n",
    "            try:\n",
    "                ncar = num.find_all('p', {\"class\": \"property-meta car\"})[0].text\n",
    "                ncar = re.search(r'[A-Za-z][ ]:[ ](.*)', ncar).group(1)\n",
    "            except IndexError:\n",
    "                ncar = 'none'\n",
    "            try:\n",
    "                address = num.find_all('h2', {\"class\":\"address\"})[0].text\n",
    "            except IndexError:\n",
    "                address = 'none'\n",
    "\n",
    "            for z in zip(rent_prices, rent_dates):\n",
    "                d = {\"address\":[address], \"latitude\":[latitude], \"longitude\":[longitude], \n",
    "                    \"nbed\":[nbed], \"nbath\":[nbath], \"ncar\":[ncar], \"historical_prices\":[z[0]], \n",
    "                    \"historical_dates\":[z[1]]}\n",
    "\n",
    "                if first:\n",
    "                    first = False\n",
    "                    data = pd.DataFrame.from_dict(d)\n",
    "                else:\n",
    "                    data = pd.concat([data, pd.DataFrame.from_dict(d)])\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return data\n",
    "\n",
    "    # print(data.head(10))\n",
    "    # data.to_csv(\"../../data/curated/historical_rent_data.csv\")\n",
    "# concat all the different dataframes created, culminating in dfa (completed dataframe)\n",
    "# result = pd.concat([df_price, df_agency], axis=1, sort=False)\n",
    "# result2 = pd.concat([result, df_postcode], axis=1, sort=False)\n",
    "# result3 = pd.concat([result2, df_bedrooms], axis=1, sort=False)\n",
    "# dfa = pd.concat([result3, df_surface], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlink = 'https://www.oldlistings.com.au/real-estate/VIC/Melbourne/3000/rent/'\n",
    "def retrive_hist(dlink, filename = \"../../data/curated/historical_rent_data_all.csv\"):\n",
    "    # specify the url format\n",
    "    # url = 'https://www.oldlistings.com.au/real-estate/VIC/Melbourne/3000/rent/' # put page number at the end\n",
    "    # initialize a list called houses \n",
    "    houses = []\n",
    "    # initialize variable count at 1\n",
    "    count = 1\n",
    "\n",
    "    # first while loop that will run 100 times (adjust this to how many pages you want to scrape)\n",
    "    while count <= 10:\n",
    "        # initialize variable new_count at 0\n",
    "        new_count = 0\n",
    "        houses = []\n",
    "        # if loop that specifies the first page separately (many websites have a first page url format different than other pages)\n",
    "        if count == 1:\n",
    "            first_page = dlink\n",
    "            # request the response\n",
    "            response = get(first_page)\n",
    "            # parse through the html \n",
    "            html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # in the html of the page, find all the bins with <li> and class:\n",
    "            house_data = html_soup.find_all('div', class_=\"content-col\")\n",
    "            # I like to print where the program is on the screen so we can follow its progress and where any errors happened\n",
    "            print(first_page)\n",
    "\n",
    "            # if the response was not empty (if something was actually scraped)\n",
    "            if house_data != []:\n",
    "                # add to the list houses\n",
    "                houses.extend(house_data)\n",
    "                # random wait times\n",
    "                value = random()\n",
    "                scaled_value = 1 + (value * (9 - 5))\n",
    "                print(scaled_value)\n",
    "                # time.sleep(scaled_value)\n",
    "        # pages other than the first\n",
    "        elif count != 1:\n",
    "        # collect four and wait random times \n",
    "            url = dlink + str(count)\n",
    "            print(url)\n",
    "            response = get(url)\n",
    "            html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            #print(response)\n",
    "            house_data = html_soup.find_all('div', class_=\"content-col\")\n",
    "\n",
    "            if house_data != []:\n",
    "                houses.extend(house_data)\n",
    "                value = random()\n",
    "                scaled_value = 1 + (value * (9 - 5))\n",
    "                # print(scaled_value)\n",
    "                # time.sleep(scaled_value)\n",
    "\n",
    "            # if you get empty response, stop the loop\n",
    "            else:\n",
    "                print('empty')\n",
    "                break\n",
    "\n",
    "        data = html_phaser(houses)\n",
    "        \n",
    "        # write the relevant info of current property one row at a time\n",
    "        with open(filename, 'a', newline='') as g:\n",
    "            thewriter = writer(g)\n",
    "            for row in data.iterrows():\n",
    "                thewriter.writerow(row)\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table link = https://www.oldlistings.com.au/site-map?state=VIC&sort=asc&order=Postcode\n",
    "\n",
    "tlink = \"https://www.oldlistings.com.au/site-map?state=VIC&sort=asc&order=Postcode\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
