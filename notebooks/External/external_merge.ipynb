{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path\n",
    "new_path = '../../data/curated/merged_dataset/'\n",
    "\n",
    "if not os.path.exists(new_path):\n",
    "    os.makedirs(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge GDP and saving rate and drop month to get values of all attributes based on year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gdp and saving rate data and predicted gdp and saving rate data\n",
    "gdp_sr = pd.read_csv('../../data/curated/gdp_with_saving_rate.csv')\n",
    "pred_gdp_sr = pd.read_csv('../../data/curated/feature_prediction/21_27_gdp_with_saving_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "for i in year:\n",
    "    if i not in [2021, 2022]:\n",
    "        data = pd.read_csv(f'../../data/curated/min_distance_sa2_organised/{i}_property_with_SA2.csv', index_col=[0])\n",
    "\n",
    "        # fill up missing distance data with maximum distance\n",
    "        max_cbd = np.nanmax(data['min_distance_to_cbd'].values)\n",
    "        max_park = np.nanmax(data['min_distance_to_park'].values)\n",
    "        max_prim = np.nanmax(data['min_distance_to_prim'].values)\n",
    "        max_second = np.nanmax(data['min_distance_to_second'].values)\n",
    "        max_train = np.nanmax(data['min_distance_to_train'].values)\n",
    "        max_poli = np.nanmax(data['min_distance_to_poli'].values)\n",
    "        max_hosp = np.nanmax(data['min_distance_to_hosp'].values)\n",
    "        max_shop = np.nanmax(data['min_distance_to_shop'].values)\n",
    "\n",
    "        data = data.fillna({'min_distance_to_cbd': max_cbd, 'min_distance_to_park': max_park, 'min_distance_to_prim': max_prim, 'min_distance_to_second': max_second, \n",
    "        'min_distance_to_train': max_train, 'min_distance_to_hosp': max_hosp, 'min_distance_to_poli': max_poli, 'min_distance_to_shop': max_shop})    \n",
    "        \n",
    "        # drop months to get values of all attributes based on year\n",
    "        data = data.groupby(['year', 'address', 'latitude', 'longitude', 'postcode',\n",
    "            'sa2_2021', 'sa2_2016', 'residence_type', 'nbed', 'nbath', 'ncar'], as_index=False)\\\n",
    "        .agg({'min_distance_to_cbd': 'first', 'min_distance_to_park': 'first', 'min_distance_to_prim': 'first', 'min_distance_to_second': 'first', 'min_distance_to_train': 'first', \n",
    "        'min_distance_to_hosp': 'first', 'min_distance_to_poli': 'first', 'min_distance_to_shop': 'first', 'weekly_rent': 'mean'})\n",
    "\n",
    "        # merge gdp and saving rate data with dataset of organised dataset (except 2021 and 2022) based on year\n",
    "        gdp = list(gdp_sr.loc[gdp_sr['year'] == i, 'gdp(USD Millioins)'])[0]\n",
    "        sr = list(gdp_sr.loc[gdp_sr['year'] == i, 'saving_rate(% of GDP)'])[0]\n",
    "        \n",
    "        data[list(gdp_sr.columns)[2]] = gdp\n",
    "        data[list(gdp_sr.columns)[3]] = sr\n",
    "\n",
    "    else:\n",
    "        data = pd.read_csv(f'../../data/curated/min_distance_sa2_organised/{i}_property_with_SA2.csv', index_col=[0])\n",
    "\n",
    "        # fill up missing distance data with maximum distance\n",
    "        max_cbd = np.nanmax(data['min_distance_to_cbd'].values)\n",
    "        max_park = np.nanmax(data['min_distance_to_park'].values)\n",
    "        max_prim = np.nanmax(data['min_distance_to_prim'].values)\n",
    "        max_second = np.nanmax(data['min_distance_to_second'].values)\n",
    "        max_train = np.nanmax(data['min_distance_to_train'].values)\n",
    "        max_poli = np.nanmax(data['min_distance_to_poli'].values)\n",
    "        max_hosp = np.nanmax(data['min_distance_to_hosp'].values)\n",
    "        max_shop = np.nanmax(data['min_distance_to_shop'].values)\n",
    "\n",
    "        data = data.fillna({'min_distance_to_cbd': max_cbd, 'min_distance_to_park': max_park, 'min_distance_to_prim': max_prim, 'min_distance_to_second': max_second, \n",
    "        'min_distance_to_train': max_train, 'min_distance_to_hosp': max_hosp, 'min_distance_to_poli': max_poli, 'min_distance_to_shop': max_shop})   \n",
    "        \n",
    "        # drop months to get values of all attributes based on year\n",
    "        data = data.groupby(['year', 'address', 'latitude', 'longitude', 'postcode',\n",
    "            'sa2_2021', 'sa2_2016', 'residence_type', 'nbed', 'nbath', 'ncar'], as_index=False)\\\n",
    "        .agg({'min_distance_to_cbd': 'first', 'min_distance_to_park': 'first', 'min_distance_to_prim': 'first', 'min_distance_to_second': 'first', 'min_distance_to_train': 'first', \n",
    "        'min_distance_to_hosp': 'first', 'min_distance_to_poli': 'first', 'min_distance_to_shop': 'first', 'weekly_rent': 'mean'})\n",
    "\n",
    "        # merge predicted gdp and saving rate data with dataset of organised dataset (2021 and 2022) based on year\n",
    "        gdp = list(pred_gdp_sr.loc[pred_gdp_sr['year'] == i, 'gdp'])[0]\n",
    "        sr = list(pred_gdp_sr.loc[pred_gdp_sr['year'] == i, 'saving'])[0]\n",
    "        \n",
    "        data[list(gdp_sr.columns)[2]] = gdp\n",
    "        data[list(gdp_sr.columns)[3]] = sr\n",
    "\n",
    "    # output csv file of merged dataset\n",
    "    data.to_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge income per person for each sa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load income per person for each sa2 and predicted income per person for each sa2 data\n",
    "income = pd.read_csv('../../data/curated/income_per_person_sa2.csv', index_col=[0])\n",
    "income = income.rename(columns={'SA2': 'sa2_2016'})\n",
    "pred_income = pd.read_csv('../../data/curated/feature_prediction/20_27_income_per_person_2016sa2.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "for i in year:\n",
    "    if i not in [2020, 2021, 2022]:\n",
    "        data = pd.read_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index_col=[0])\n",
    "\n",
    "        # merge income per person for each sa2 with dataset of organised dataset (except 2020, 2021 and 2022) based on 2016 sa2\n",
    "        income_data = income.loc[:, ['sa2_2016', str(i)]]\n",
    "\n",
    "        data['income_per_person'] = (data.merge(income_data, on=['sa2_2016'], how='left')[str(i)])\n",
    "\n",
    "    else:\n",
    "        data = pd.read_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index_col=[0])\n",
    "\n",
    "        # merge predicted income per person for each sa2 with dataset of organised dataset (2020, 2021 and 2022) based on 2016 sa2\n",
    "        income_data = pred_income.loc[pred_income['Year'] == i][['sa2_2016', 'income_per_person_sa2']]\n",
    "\n",
    "        data['income_per_person'] = (data.merge(income_data, on=['sa2_2016'], how='left')['income_per_person_sa2'])\n",
    "\n",
    "    data.to_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge population density for each sa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('../../data/curated/vic_population_density_sa2.csv', index_col=[0])\n",
    "population = population.rename(columns={'SA2 code': 'sa2_2021'})\n",
    "pred_population = pd.read_csv('../../data/curated/feature_prediction/22_27_population.csv', index_col=[0])\n",
    "pred_population = pred_population.rename(columns={'SA2 code': 'sa2_2021'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "for i in year:\n",
    "    if i != 2022:\n",
    "        data = pd.read_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index_col=[0])\n",
    "\n",
    "        population_data = population.loc[:, ['sa2_2021', f'population_density_of_{str(i)}']]\n",
    "\n",
    "        data['population_density'] = (data.merge(population_data, on=['sa2_2021'], how='left')[f'population_density_of_{str(i)}'])\n",
    "\n",
    "    else:\n",
    "        data = pd.read_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index_col=[0])\n",
    "        \n",
    "        population_data = pred_population.loc[pred_population['year'] == i][['sa2_2021', 'pred']]\n",
    "\n",
    "        data['population_density'] = (data.merge(population_data, on=['sa2_2021'], how='left')['pred'])\n",
    "\n",
    "    data.to_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crime cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>postcode</th>\n",
       "      <th>Offence Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>3000</td>\n",
       "      <td>17553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>3002</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>3003</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>3004</td>\n",
       "      <td>5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>3006</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>2022</td>\n",
       "      <td>3990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>2022</td>\n",
       "      <td>3991</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>2022</td>\n",
       "      <td>3992</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>2022</td>\n",
       "      <td>3995</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893</th>\n",
       "      <td>2022</td>\n",
       "      <td>3996</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6894 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  postcode  Offence Count\n",
       "0     2013      3000          17553\n",
       "1     2013      3002            933\n",
       "2     2013      3003            837\n",
       "3     2013      3004           5305\n",
       "4     2013      3006           2433\n",
       "...    ...       ...            ...\n",
       "6889  2022      3990              2\n",
       "6890  2022      3991             75\n",
       "6891  2022      3992             94\n",
       "6892  2022      3995           1179\n",
       "6893  2022      3996            254\n",
       "\n",
       "[6894 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_cases = pd.read_csv('../../data/curated/crime_cases.csv', index_col=[0])\n",
    "crime_cases = crime_cases.rename(columns={'Postcode': 'postcode'})\n",
    "crime_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "for i in year:\n",
    "    data = pd.read_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index_col=[0])\n",
    "\n",
    "    crime_cases_data = crime_cases.loc[crime_cases['Year'] == i][['postcode', 'Offence Count']]\n",
    "\n",
    "    data['crime_cases'] = (data.merge(crime_cases_data, on=['postcode'], how='left')['Offence Count'])\n",
    "\n",
    "    data.to_csv(f'../../data/curated/merged_dataset/{i}_merged_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
