{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = r'../data/curated/merged_dataset/' # use your path\n",
    "all_files = glob.glob(os.path.join(path , \"*.csv\"))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in sorted(all_files):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "merged_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "merged_df.drop(['address', 'latitude', 'longitude', 'postcode', 'sa2_2016', 'gdp(USD Millioins)'], axis=1, inplace=True)\n",
    "merged_df['income_per_person'] = np.log(merged_df['income_per_person'])\n",
    "merged_df['crime_cases'] = np.log(merged_df['crime_cases'])\n",
    "merged_df['weekly_rent'] = np.log(merged_df['weekly_rent'])\n",
    "# df = merged_df[merged_df.duplicated(subset=[\"sa2_2021\", \"nbed\", \"nbath\", \"ncar\", \"residence_type\"], keep=False)]\n",
    "df = merged_df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137614 training instances, 34404 test instances\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_COLS = ['weekly_rent']\n",
    "COLS = list(df.columns)\n",
    "df = df[COLS]\n",
    "df = pd.get_dummies(df, columns=['residence_type', 'sa2_2021', 'nbed', 'nbath', 'ncar'])\n",
    "\n",
    "train, test = train_test_split(df, train_size=0.8, random_state=0)\n",
    "\n",
    "X_train, y_train = train.drop(TARGET_COLS, axis=1), train[TARGET_COLS]\n",
    "X_test, y_test = test.drop(TARGET_COLS, axis=1), test[TARGET_COLS]\n",
    "\n",
    "print(f'{len(X_train)} training instances, {len(X_test)} test instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>min_distance_to_cbd</th>\n",
       "      <th>min_distance_to_park</th>\n",
       "      <th>min_distance_to_prim</th>\n",
       "      <th>min_distance_to_second</th>\n",
       "      <th>min_distance_to_train</th>\n",
       "      <th>min_distance_to_hosp</th>\n",
       "      <th>min_distance_to_poli</th>\n",
       "      <th>min_distance_to_shop</th>\n",
       "      <th>weekly_rent</th>\n",
       "      <th>...</th>\n",
       "      <th>ncar_0</th>\n",
       "      <th>ncar_1</th>\n",
       "      <th>ncar_2</th>\n",
       "      <th>ncar_3</th>\n",
       "      <th>ncar_4</th>\n",
       "      <th>ncar_5</th>\n",
       "      <th>ncar_6</th>\n",
       "      <th>ncar_7</th>\n",
       "      <th>ncar_8</th>\n",
       "      <th>ncar_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>227.97163</td>\n",
       "      <td>23.16035</td>\n",
       "      <td>7.35747</td>\n",
       "      <td>16.96507</td>\n",
       "      <td>35.56825</td>\n",
       "      <td>21.35025</td>\n",
       "      <td>22.04660</td>\n",
       "      <td>9.35209</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>223.66084</td>\n",
       "      <td>5.71742</td>\n",
       "      <td>6.50536</td>\n",
       "      <td>6.76794</td>\n",
       "      <td>7.54355</td>\n",
       "      <td>7.42972</td>\n",
       "      <td>6.28177</td>\n",
       "      <td>9.35209</td>\n",
       "      <td>5.370638</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>243.25680</td>\n",
       "      <td>5.11222</td>\n",
       "      <td>0.20027</td>\n",
       "      <td>36.72106</td>\n",
       "      <td>50.85341</td>\n",
       "      <td>36.63541</td>\n",
       "      <td>0.08478</td>\n",
       "      <td>9.35209</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>140.35827</td>\n",
       "      <td>78.32509</td>\n",
       "      <td>10.66523</td>\n",
       "      <td>11.91899</td>\n",
       "      <td>11.26906</td>\n",
       "      <td>177.44731</td>\n",
       "      <td>84.47341</td>\n",
       "      <td>9.35209</td>\n",
       "      <td>5.857933</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>13.86135</td>\n",
       "      <td>0.93250</td>\n",
       "      <td>1.32931</td>\n",
       "      <td>3.49174</td>\n",
       "      <td>2.20800</td>\n",
       "      <td>177.44731</td>\n",
       "      <td>84.47341</td>\n",
       "      <td>3.96501</td>\n",
       "      <td>5.616771</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172030</th>\n",
       "      <td>2022</td>\n",
       "      <td>293.28053</td>\n",
       "      <td>0.56012</td>\n",
       "      <td>1.21809</td>\n",
       "      <td>114.77016</td>\n",
       "      <td>90.08591</td>\n",
       "      <td>140.56888</td>\n",
       "      <td>74.35608</td>\n",
       "      <td>13.64920</td>\n",
       "      <td>5.579730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172031</th>\n",
       "      <td>2022</td>\n",
       "      <td>258.29111</td>\n",
       "      <td>3.49087</td>\n",
       "      <td>5.08707</td>\n",
       "      <td>3.60570</td>\n",
       "      <td>8.37185</td>\n",
       "      <td>2.60312</td>\n",
       "      <td>74.35608</td>\n",
       "      <td>13.64920</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172032</th>\n",
       "      <td>2022</td>\n",
       "      <td>9.47077</td>\n",
       "      <td>2.45011</td>\n",
       "      <td>1.33931</td>\n",
       "      <td>1.62322</td>\n",
       "      <td>3.63291</td>\n",
       "      <td>140.56888</td>\n",
       "      <td>74.35608</td>\n",
       "      <td>1.97636</td>\n",
       "      <td>6.620073</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172033</th>\n",
       "      <td>2022</td>\n",
       "      <td>1.84933</td>\n",
       "      <td>0.65199</td>\n",
       "      <td>1.10438</td>\n",
       "      <td>1.27940</td>\n",
       "      <td>1.87840</td>\n",
       "      <td>140.56888</td>\n",
       "      <td>74.35608</td>\n",
       "      <td>13.64920</td>\n",
       "      <td>6.013715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172034</th>\n",
       "      <td>2022</td>\n",
       "      <td>4.58626</td>\n",
       "      <td>0.48042</td>\n",
       "      <td>0.49588</td>\n",
       "      <td>1.47456</td>\n",
       "      <td>1.29233</td>\n",
       "      <td>140.56888</td>\n",
       "      <td>1.38884</td>\n",
       "      <td>13.64920</td>\n",
       "      <td>5.899897</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172018 rows × 551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  min_distance_to_cbd  min_distance_to_park  min_distance_to_prim  \\\n",
       "0       2013            227.97163              23.16035               7.35747   \n",
       "1       2013            223.66084               5.71742               6.50536   \n",
       "2       2013            243.25680               5.11222               0.20027   \n",
       "3       2013            140.35827              78.32509              10.66523   \n",
       "4       2013             13.86135               0.93250               1.32931   \n",
       "...      ...                  ...                   ...                   ...   \n",
       "172030  2022            293.28053               0.56012               1.21809   \n",
       "172031  2022            258.29111               3.49087               5.08707   \n",
       "172032  2022              9.47077               2.45011               1.33931   \n",
       "172033  2022              1.84933               0.65199               1.10438   \n",
       "172034  2022              4.58626               0.48042               0.49588   \n",
       "\n",
       "        min_distance_to_second  min_distance_to_train  min_distance_to_hosp  \\\n",
       "0                     16.96507               35.56825              21.35025   \n",
       "1                      6.76794                7.54355               7.42972   \n",
       "2                     36.72106               50.85341              36.63541   \n",
       "3                     11.91899               11.26906             177.44731   \n",
       "4                      3.49174                2.20800             177.44731   \n",
       "...                        ...                    ...                   ...   \n",
       "172030               114.77016               90.08591             140.56888   \n",
       "172031                 3.60570                8.37185               2.60312   \n",
       "172032                 1.62322                3.63291             140.56888   \n",
       "172033                 1.27940                1.87840             140.56888   \n",
       "172034                 1.47456                1.29233             140.56888   \n",
       "\n",
       "        min_distance_to_poli  min_distance_to_shop  weekly_rent  ...  ncar_0  \\\n",
       "0                   22.04660               9.35209     5.703782  ...       1   \n",
       "1                    6.28177               9.35209     5.370638  ...       1   \n",
       "2                    0.08478               9.35209     5.164786  ...       1   \n",
       "3                   84.47341               9.35209     5.857933  ...       1   \n",
       "4                   84.47341               3.96501     5.616771  ...       1   \n",
       "...                      ...                   ...          ...  ...     ...   \n",
       "172030              74.35608              13.64920     5.579730  ...       0   \n",
       "172031              74.35608              13.64920     6.214608  ...       0   \n",
       "172032              74.35608               1.97636     6.620073  ...       0   \n",
       "172033              74.35608              13.64920     6.013715  ...       0   \n",
       "172034               1.38884              13.64920     5.899897  ...       0   \n",
       "\n",
       "        ncar_1  ncar_2  ncar_3  ncar_4  ncar_5  ncar_6  ncar_7  ncar_8  ncar_9  \n",
       "0            0       0       0       0       0       0       0       0       0  \n",
       "1            0       0       0       0       0       0       0       0       0  \n",
       "2            0       0       0       0       0       0       0       0       0  \n",
       "3            0       0       0       0       0       0       0       0       0  \n",
       "4            0       0       0       0       0       0       0       0       0  \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "172030       1       0       0       0       0       0       0       0       0  \n",
       "172031       0       1       0       0       0       0       0       0       0  \n",
       "172032       1       0       0       0       0       0       0       0       0  \n",
       "172033       1       0       0       0       0       0       0       0       0  \n",
       "172034       1       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[172018 rows x 551 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Normalization\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor # Deprecated\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model():\n",
    "    \"\"\"Base neural network model for AdaBoosting\"\"\"\n",
    "    norm_layer = Normalization()\n",
    "    norm_layer.adapt(X_train)\n",
    "    model = keras.Sequential(\n",
    "        [   \n",
    "            norm_layer,                   # our normalisation layer recieves the input\n",
    "            Dense(80, activation='relu'),  # the hidden layer gets the normalised result\n",
    "            Dense(80, activation='relu'),  # (in case you want to try an extra hidden layer)\n",
    "            Dense(1, activation='relu')\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer='adam',  # Adam optimises using gradient descent, is generally fast and a good choice in many cases\n",
    "        loss='MSE' # 'sparse_categorical_crossentropy'#'MSE'  # Mean Squared Error makes sense for this problem, \n",
    "                    # though we could use Mean Absolute Error, or many other choices.\n",
    "                    # Classification outputs would use a different loss (eg. BinaryCrossentropy)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     x=X_train,\n",
    "#     y=y_train,\n",
    "#     batch_size=16,\n",
    "#     validation_split=0.25,\n",
    "#     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(base_estimator=KerasRegressor(batch_size=10, epochs=10, model=&lt;function simple_model at 0x3147ed3f0&gt;, verbose=0))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(base_estimator=KerasRegressor(batch_size=10, epochs=10, model=&lt;function simple_model at 0x3147ed3f0&gt;, verbose=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function simple_model at 0x3147ed3f0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=10\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function simple_model at 0x3147ed3f0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=10\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=10\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(base_estimator=KerasRegressor(batch_size=10, epochs=10, model=<function simple_model at 0x3147ed3f0>, verbose=0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_estimator = KerasRegressor(model=simple_model, epochs=10, batch_size=10, verbose=0)\n",
    "boosted_ann = AdaBoostRegressor(base_estimator= ann_estimator)\n",
    "boosted_ann.fit(X_train, y_train.values.ravel())# scale your training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = boosted_ann.predict(X_test.iloc[:])\n",
    "# errors = np.array(predictions - y_test.iloc[:])\n",
    "# squared_errors = errors**2\n",
    "# mean_squared_error = squared_errors.mean()\n",
    "# \n",
    "# print(f'MSE: {mean_squared_error}')\n",
    "# tot_sum_squares = (np.array(y_test - y_test.mean())**2).sum()\n",
    "# r2 = 1 - (squared_errors.sum() / tot_sum_squares)\n",
    "# print(f'Model R^2: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3287598.945886227\n",
      "Model R^2: -758781499232.5344\n"
     ]
    }
   ],
   "source": [
    "predictions = boosted_ann.predict(X_test.iloc[:])\n",
    "errors = predictions - np.array(y_test.iloc[:])\n",
    "squared_errors = errors**2\n",
    "mean_squared_error = squared_errors.mean()\n",
    "\n",
    "print(f'MSE: {mean_squared_error}')\n",
    "tot_sum_squares = (np.array(y_test - y_test.mean())**2).sum()\n",
    "r2 = 1 - (squared_errors.sum() / tot_sum_squares)\n",
    "print(f'Model R^2: {r2:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddc0034ad7dea0900e87274559c7f730dcb76ce48c43b93b61df066c264fb9ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
