{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "path = r'../data/curated/merged_dataset/' # use your path\n",
    "all_files = glob.glob(os.path.join(path , \"*.csv\"))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in sorted(all_files):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "merged_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "merged_df.drop(['address', 'latitude', 'longitude', 'postcode', 'sa2_2016'], axis=1, inplace=True)\n",
    "print(merged_df.columns)\n",
    "merged_df\n",
    "for col in merged_df.columns:\n",
    "    if col not in ['residence_type', 'year']:\n",
    "        merged_df[col] = merged_df[col].astype(float)\n",
    "merged_df['year'] = merged_df['year'].astype(int)\n",
    "#pd.get_dummies(merged_df['sa2_2021'])\n",
    "merged_df.rename({'gdp(USD Millioins)': 'gdp', 'saving_rate(% of GDP)': 'saving_rate'}, axis=1, inplace=True)\n",
    "merged_df['residence_type'] = merged_df['residence_type'].astype('category')\n",
    "merged_df['residence_type'] = merged_df['residence_type'].cat.codes\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "y = merged_df['weekly_rent']\n",
    "#merged_df.drop(['weekly_rent', 'year'], axis=1, inplace=True)\n",
    "merged_df.drop('weekly_rent', axis=1, inplace=True)\n",
    "X = merged_df\n",
    "print(X)\n",
    "sel = RandomForestRegressor(n_estimators = 100)\n",
    "sel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory\n",
    "directory = \"random_forest_pred\"\n",
    "  \n",
    "# Parent Directory path\n",
    "parent_dir = \"../data/curated/\"\n",
    "# Path\n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "# Create the directory\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the next 5 years\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Check the accuracy before predicting with the trained random forest regressor\n",
    "# Predict for the next 5 years\n",
    "parent_dir = \"../data/curated/2023_2027_data\"\n",
    "\n",
    "for filename in os.listdir(parent_dir):\n",
    "    merged_df_yr = spark.read.csv(parent_dir + \"/\" + filename, header=True)\n",
    "\n",
    "    # Extract year from the file name \n",
    "    which_year = re.findall(r'\\d+', filename)\n",
    "\n",
    "    # Add year column to the dataset to fit the input into the model\n",
    "    merged_df_yr = merged_df_yr.withColumn(\"year\", lit(which_year[0]))\n",
    "\n",
    "    for c in merged_df_yr.columns:\n",
    "        if c not in [\"year\", \"sa2_2021\"]:\n",
    "            merged_df_yr = merged_df_yr.withColumn(c,merged_df_yr[c].cast(FloatType())) \n",
    "        elif c in [\"year\", \"sa2_2021\"]:\n",
    "            merged_df_yr = merged_df_yr.withColumn(c,merged_df_yr[c].cast(IntegerType())) \n",
    "\n",
    "    merged_df_yr = merged_df_yr.toPandas()\n",
    "    print(merged_df_yr[\"sa2_2021\"])\n",
    "    merged_df_yr.rename(columns = {'gdp(USD Millioins)':'gdp', 'saving_rate(% of GDP)':'saving_rate'}, inplace = True)\n",
    "    merged_df_yr['residence_type'] = merged_df_yr['residence_type'].astype('category')\n",
    "    merged_df_yr['residence_type'] = merged_df_yr['residence_type'].cat.codes\n",
    "    merged_df_yr.dropna(inplace=True)\n",
    "\n",
    "    # Reorder the columns \n",
    "    merged_df_yr_reordered = merged_df_yr[['year', 'sa2_2021', 'residence_type', 'nbed', 'nbath', 'ncar',\n",
    "       'min_distance_to_cbd', 'min_distance_to_park', 'min_distance_to_prim',\n",
    "       'min_distance_to_second', 'min_distance_to_train',\n",
    "       'min_distance_to_hosp', 'min_distance_to_poli', 'min_distance_to_shop',\n",
    "       'gdp', 'saving_rate', 'income_per_person', 'population_density',\n",
    "       'crime_cases']]\n",
    "\n",
    "    # Predict with random forest tree\n",
    "    prediction = sel.predict(merged_df_yr_reordered)\n",
    "\n",
    "    new_csv_name = \"../data/curated/random_forest_pred/\" + filename\n",
    "    print(merged_df_yr_reordered['sa2_2021'].astype(int))\n",
    "    data = {'year': merged_df_yr_reordered['year'],\n",
    "            'sa2_2021': merged_df_yr_reordered['sa2_2021'],\n",
    "            'predicted_price': prediction }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "    df.to_csv(new_csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
